{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEC_PER_MIN = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Lyric Label\n",
    "Author: Jason Xu\n",
    "\n",
    "    :format: name.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics_label(dev=False):\n",
    "    if dev:\n",
    "        path = os.getcwd() + '\\\\Model_Data\\\\dev\\\\lyrics'\n",
    "    else:\n",
    "        path = os.getcwd() + '\\\\Model_Data\\\\train\\\\lyrics'\n",
    "    # train data\n",
    "    for filename in glob.glob(os.path.join(path, '*.txt')):\n",
    "        with open(filename, 'r') as r:\n",
    "            lines = r.readlines()\n",
    "            label_list = [0] * 2 * SEC_PER_MIN \n",
    "            for line in lines:\n",
    "                timestamp = re.split(r'\\[|\\]', line)[1]\n",
    "                time = re.split(r'[.:]', timestamp)\n",
    "                # time format: [min, sec, minisec]\n",
    "                if int(time[0]) < 2:\n",
    "                    sec = int(time[1]) + int(time[0]) * SEC_PER_MIN \n",
    "                    label_list[sec] = 1\n",
    "            with open(filename.split('.')[0] + \".label\", 'w') as w:\n",
    "                w.write(' '.join(str(s) for s in label_list))\n",
    "                w.close()\n",
    "        r.close()\n",
    "\n",
    "\n",
    "# Train\n",
    "generate_lyrics_label()\n",
    "# Dev\n",
    "generate_lyrics_label(dev=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip .wav file with labels\n",
    "Author: Jason Xu\n",
    "    \n",
    "    :output: \n",
    "        label_torch (tensor of lyric label)\n",
    "        reg_wav_list (wav, sr) from librosa load\n",
    "        iso_wav_list (wav, sr) from librosa load         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Train Data =====\n",
      "(31, 120)\n",
      "Loading file: ABoyNamedSue.wav\n",
      "Loading file: AintNoGrave.wav\n",
      "Loading file: AlohaOe.wav\n",
      "Loading file: ASatisfiedMind.wav\n",
      "Loading file: DannyBoy.wav\n",
      "Loading file: Desperado.wav\n",
      "Loading file: FatherAndSon.wav\n",
      "Loading file: FurtherOnUpTheRoad.wav\n",
      "Loading file: GhostRidersInTheSky.wav\n",
      "Loading file: GirlFromTheNorthCountry.wav\n",
      "Loading file: GiveMyLoveToRose.wav\n",
      "Loading file: Hurt.wav\n",
      "Loading file: IDontHurtAnymore.wav\n",
      "Loading file: IHeardThatLonesomeWhistle.wav\n",
      "Loading file: InMyLife.wav\n",
      "Loading file: IWontBackDown.wav\n",
      "Loading file: ManInBlack.wav\n",
      "Loading file: One.wav\n",
      "Loading file: OutAmongTheStars.wav\n",
      "Loading file: PersonalJesus.wav\n",
      "Loading file: RingOfFire.wav\n",
      "Loading file: SheUsedToLoveMeALot.wav\n",
      "Loading file: SolitaryMan.wav\n",
      "Loading file: TheGeneralLee.wav\n",
      "Loading file: TheGettysburgAddress.wav\n",
      "Loading file: TheLegendOfJohnHenrysHammer.wav\n",
      "Loading file: TheManComesAround.wav\n",
      "Loading file: TheWanderer.wav\n",
      "Loading file: WayfaringStranger.wav\n",
      "Loading file: WellMeetAgain.wav\n",
      "Loading file: YouAreMySunshine.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_19964\\3462810147.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  reg_wav_list = np.array(reg_wav_list)\n",
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_19964\\3462810147.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  iso_wav_list = np.array(iso_wav_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dev Data =====\n",
      "(7, 120)\n",
      "Loading file: BlueSuedeShoes.wav\n",
      "Loading file: FolsomPrisonBlues.wav\n",
      "Loading file: GodsGonnaCutYouDown.wav\n",
      "Loading file: HeartOfGold.wav\n",
      "Loading file: Highwayman..wav\n",
      "Loading file: OhLonesomeMe.wav\n",
      "Loading file: RedemptionSong.wav\n"
     ]
    }
   ],
   "source": [
    "def zip_label_wav(dev=False):\n",
    "    if dev:\n",
    "        reg_dir = os.getcwd() + '\\\\Model_Data\\\\dev\\\\songs\\\\vocal_reg\\\\'\n",
    "        iso_dir = os.getcwd() + '\\\\Model_Data\\\\dev\\\\songs\\\\vocal_iso\\\\'\n",
    "        label_dir = os.getcwd() + '\\\\Model_Data\\\\dev\\\\lyrics\\\\'\n",
    "    else:\n",
    "        reg_dir = os.getcwd() + '\\\\Model_Data\\\\train\\\\songs\\\\vocal_reg\\\\'\n",
    "        iso_dir = os.getcwd() + '\\\\Model_Data\\\\train\\\\songs\\\\vocal_iso\\\\'\n",
    "        label_dir = os.getcwd() + '\\\\Model_Data\\\\train\\\\lyrics\\\\'\n",
    "    reg_wav_list = []\n",
    "    iso_wav_list = []\n",
    "    label_list = []\n",
    "    # .label file\n",
    "    for filename in os.scandir(reg_dir):\n",
    "        with open(label_dir + filename.name.split('.')[0] + '.label', 'r') as r:\n",
    "            line = r.readline()\n",
    "            label_list.append(str(line).split(' '))\n",
    "        r.close()\n",
    "    label_torch = np.array(label_list, dtype=np.float32)\n",
    "    print(np.shape(label_torch))\n",
    "    # .wav file\n",
    "    for filename in os.scandir(reg_dir):\n",
    "        print(\"Loading file:\", filename.name)\n",
    "        reg_wav, reg_sr = librosa.load(filename.path, duration=120)\n",
    "        iso_wav, iso_sr = librosa.load(iso_dir + filename.name, duration=120)\n",
    "        reg_wav_list.append((reg_wav, reg_sr))\n",
    "        iso_wav_list.append((iso_wav, iso_sr))\n",
    "    reg_wav_list = np.array(reg_wav_list)\n",
    "    iso_wav_list = np.array(iso_wav_list)\n",
    "    return label_torch, reg_wav_list, iso_wav_list\n",
    "\n",
    "# train\n",
    "print(\"===== Train Data =====\")\n",
    "label_torch, reg_wav_list, iso_wav_list = zip_label_wav()\n",
    "# dev\n",
    "print(\"===== Dev Data =====\")\n",
    "dev_label_torch, dev_reg_wav_list, dev_iso_wav_list = zip_label_wav(dev=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "Author: Andy Barbaro (main part), Jason Xu(prediction and eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training Model =====\n",
      "Epoch 0 Total Loss: 1831.873\n",
      "Epoch 1 Total Loss: 1735.390\n",
      "Epoch 2 Total Loss: 1731.908\n",
      "Epoch 3 Total Loss: 1725.466\n",
      "Epoch 4 Total Loss: 1723.628\n",
      "Epoch 5 Total Loss: 1718.118\n",
      "Epoch 6 Total Loss: 1712.236\n",
      "Epoch 7 Total Loss: 1711.441\n",
      "Epoch 8 Total Loss: 1698.585\n",
      "Epoch 9 Total Loss: 1703.173\n",
      "Epoch 10 Total Loss: 1696.295\n",
      "Epoch 11 Total Loss: 1692.317\n",
      "Epoch 12 Total Loss: 1681.115\n",
      "Epoch 13 Total Loss: 1684.543\n",
      "Epoch 14 Total Loss: 1673.011\n",
      "Epoch 15 Total Loss: 1668.343\n",
      "Epoch 16 Total Loss: 1670.783\n",
      "Epoch 17 Total Loss: 1657.503\n",
      "Epoch 18 Total Loss: 1647.034\n",
      "Epoch 19 Total Loss: 1659.635\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build the neural network for classifying pauses against nonpauses\n",
    "class PauseNet1(nn.Module):\n",
    "  def __init__(self, num_mfccs, hid1, hid2, out, dp=0.1):\n",
    "    super().__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.relu = nn.ReLU()\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(num_mfccs, hid1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hid1, hid2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hid2, out),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    # self.fc1 = nn.Linear(num_mfccs, hid1)\n",
    "    # torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    # self.fc2 = nn.Linear(hid1, hid2)\n",
    "    # torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    # self.fc3 = nn.Linear(hid2, hid3)\n",
    "    # torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    # self.fc4 = nn.Linear(hid3, out)\n",
    "    # torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "\n",
    "  # pass forward for nn\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "    \n",
    "\n",
    "#set parameters\n",
    "num_epochs = 20\n",
    "num_mfccs = 20\n",
    "hidden1_size = 100\n",
    "hidden2_size = 25\n",
    "out_size = 1\n",
    "\n",
    "# set other constants\n",
    "sr = 22050\n",
    "hop_length = 512\n",
    "song_dur = 120\n",
    "\n",
    "# create neural network\n",
    "pause_net = PauseNet1(num_mfccs, hidden1_size, hidden2_size, out_size)\n",
    "optimizer = optim.Adam(pause_net.parameters(), lr=0.001)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "print('===== Training Model =====')\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle\n",
    "    indices = np.arange(reg_wav_list.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    reg_wav_list = reg_wav_list[indices]\n",
    "    label_torch = label_torch[indices]\n",
    "    total_loss = 0\n",
    "    # Train data: label_torch, reg_wav_list, iso_wav_list\n",
    "    for song_sr, labels in zip(reg_wav_list, label_torch):\n",
    "        song = song_sr[0]\n",
    "        # sample window of 2048 and hop size of 512 samples\n",
    "        mfccs = librosa.feature.mfcc(y=song, n_mfcc=num_mfccs) #(num_mfccs, 5168)\n",
    "\n",
    "        #breaks down mfccs into their time intervals\n",
    "        audio_length = len(song) / sr # in seconds\n",
    "        step = hop_length / sr # in seconds\n",
    "        intervals_s = np.arange(0, audio_length, step)\n",
    "\n",
    "        # get each second and sample\n",
    "        for i, label in enumerate(labels):\n",
    "            #isolate a single second\n",
    "            sec_interval = np.where(intervals_s.astype(int) == i)[0]\n",
    "            # indexes a single second of song from MFCCs\n",
    "            song_sec = np.take(mfccs, sec_interval, axis=1)\n",
    "\n",
    "            #average the values over a second\n",
    "            inp = torch.from_numpy(np.mean(song_sec, axis=1))\n",
    "\n",
    "            label_tensor = torch.tensor([label])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = pause_net.forward(inp)\n",
    "            #print(pred)\n",
    "\n",
    "            # nonpause proper label is 0, pause proper label is 1\n",
    "            loss = loss_func(pred, label_tensor)\n",
    "            total_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"Epoch %i Total Loss: %.3f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluating =====\n",
      "Accuracy: 65 / 120 = 0.541667;\n",
      "Precision (fraction of predicted positives that are correct): 13 / 56 = 0.232143;\n",
      "Recall (fraction of true positives predicted correctly): 13 / 25 = 0.520000;\n",
      "F1 (harmonic mean of precision and recall): 0.320988;\n",
      "\n",
      "Accuracy: 88 / 120 = 0.733333;\n",
      "Precision (fraction of predicted positives that are correct): 4 / 16 = 0.250000;\n",
      "Recall (fraction of true positives predicted correctly): 4 / 24 = 0.166667;\n",
      "F1 (harmonic mean of precision and recall): 0.200000;\n",
      "\n",
      "Accuracy: 59 / 120 = 0.491667;\n",
      "Precision (fraction of predicted positives that are correct): 30 / 88 = 0.340909;\n",
      "Recall (fraction of true positives predicted correctly): 30 / 33 = 0.909091;\n",
      "F1 (harmonic mean of precision and recall): 0.495868;\n",
      "\n",
      "Accuracy: 94 / 120 = 0.783333;\n",
      "Precision (fraction of predicted positives that are correct): 4 / 17 = 0.235294;\n",
      "Recall (fraction of true positives predicted correctly): 4 / 17 = 0.235294;\n",
      "F1 (harmonic mean of precision and recall): 0.235294;\n",
      "\n",
      "Accuracy: 62 / 120 = 0.516667;\n",
      "Precision (fraction of predicted positives that are correct): 8 / 56 = 0.142857;\n",
      "Recall (fraction of true positives predicted correctly): 8 / 18 = 0.444444;\n",
      "F1 (harmonic mean of precision and recall): 0.216216;\n",
      "\n",
      "Accuracy: 63 / 120 = 0.525000;\n",
      "Precision (fraction of predicted positives that are correct): 14 / 62 = 0.225806;\n",
      "Recall (fraction of true positives predicted correctly): 14 / 23 = 0.608696;\n",
      "F1 (harmonic mean of precision and recall): 0.329412;\n",
      "\n",
      "Accuracy: 95 / 120 = 0.791667;\n",
      "Precision (fraction of predicted positives that are correct): 4 / 17 = 0.235294;\n",
      "Recall (fraction of true positives predicted correctly): 4 / 16 = 0.250000;\n",
      "F1 (harmonic mean of precision and recall): 0.242424;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== Evaluating =====')\n",
    "# Dev Data: dev_label_torch, dev_reg_wav_list, dev_iso_wav_list \n",
    "pred_seq = []\n",
    "for songs, labels in zip(dev_reg_wav_list, dev_label_torch):\n",
    "    song = songs[0]\n",
    "    # sample window of 2048 and hop size of 512 samples\n",
    "    mfccs = librosa.feature.mfcc(y=song, n_mfcc=num_mfccs) #(num_mfccs, 5168)\n",
    "\n",
    "    #breaks down mfccs into their time intervals\n",
    "    audio_length = len(song) / sr # in seconds\n",
    "    step = hop_length / sr # in seconds\n",
    "    intervals_s = np.arange(0, audio_length, step)\n",
    "    pred_list = []\n",
    "    # get each second and sample\n",
    "    for i, __ in enumerate(labels):\n",
    "        #isolate a single second\n",
    "        sec_interval = np.where(intervals_s.astype(int) == i)[0]\n",
    "        # indexes a single second of song from MFCCs\n",
    "        song_sec = np.take(mfccs, sec_interval, axis=1)\n",
    "\n",
    "        #average the values over a second\n",
    "        inp = torch.from_numpy(np.mean(song_sec, axis=1))\n",
    "        \n",
    "        pred = pause_net.forward(inp)\n",
    "        #print(pred)\n",
    "        pred = 1 if pred > 0.22 else 0\n",
    "        pred_list.append(pred)\n",
    "    pred_seq.append(pred_list)\n",
    "labels = np.array(pred_seq)\n",
    "# Eval\n",
    "for predictions, golds in zip(labels, dev_label_torch):\n",
    "    num_correct = 0\n",
    "    num_pos_correct = 0\n",
    "    num_pred = 0\n",
    "    num_gold = 0\n",
    "    num_total = 0\n",
    "    if len(golds) != len(predictions):\n",
    "        raise Exception(\"Mismatched gold/pred lengths: %i / %i\" % (len(golds), len(predictions)))\n",
    "    for idx in range(0, len(golds)):\n",
    "        gold = golds[idx]\n",
    "        prediction = predictions[idx]\n",
    "        if prediction == gold:\n",
    "            num_correct += 1\n",
    "        if prediction == 1:\n",
    "            num_pred += 1\n",
    "        if gold == 1:\n",
    "            num_gold += 1\n",
    "        if prediction == 1 and gold == 1:\n",
    "            num_pos_correct += 1\n",
    "        num_total += 1\n",
    "    acc = float(num_correct) / num_total\n",
    "    output_str = \"Accuracy: %i / %i = %f\" % (num_correct, num_total, acc)\n",
    "    prec = float(num_pos_correct) / num_pred if num_pred > 0 else 0.0\n",
    "    rec = float(num_pos_correct) / num_gold if num_gold > 0 else 0.0\n",
    "    f1 = 2 * prec * rec / (prec + rec) if prec > 0 and rec > 0 else 0.0\n",
    "    output_str += \";\\nPrecision (fraction of predicted positives that are correct): %i / %i = %f\" % (num_pos_correct, num_pred, prec)\n",
    "    output_str += \";\\nRecall (fraction of true positives predicted correctly): %i / %i = %f\" % (num_pos_correct, num_gold, rec)\n",
    "    output_str += \";\\nF1 (harmonic mean of precision and recall): %f;\\n\" % f1\n",
    "    print(output_str)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52469ae204d1d50c448c04334a11ed7bbfc3a11760631521f4bdc0e8f20089d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

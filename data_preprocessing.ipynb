{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEC_PER_MIN = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Lyric Label\n",
    "    \n",
    "    :format: name.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics_label():\n",
    "    for filename in glob.glob(os.path.join(os.getcwd() + '\\Model_Data\\lyrics', '*.txt')):\n",
    "        with open(filename, 'r') as r:\n",
    "            lines = r.readlines()\n",
    "            label_list = [0] * 2 * SEC_PER_MIN \n",
    "            for line in lines:\n",
    "                timestamp = re.split(r'\\[|\\]', line)[1]\n",
    "                time = re.split(r'[.:]', timestamp)\n",
    "                # time format: [min, sec, minisec]\n",
    "                if int(time[0]) < 2:\n",
    "                    sec = int(time[1]) + int(time[0]) * SEC_PER_MIN \n",
    "                    label_list[sec] = 1\n",
    "            with open(filename.split('.')[0] + \".label\", 'w') as w:\n",
    "                w.write(' '.join(str(s) for s in label_list))\n",
    "                w.close()\n",
    "        r.close()\n",
    "\n",
    "generate_lyrics_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip .wav file with labels\n",
    "    \n",
    "    :output: \n",
    "        label_torch (tensor of lyric label)\n",
    "        reg_wav_list (wav, sr) from librosa load\n",
    "        iso_wav_list (wav, sr) from librosa load         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 120])\n",
      "Loading file: ABoyNamedSue.wav\n",
      "Loading file: AintNoGrave.wav\n",
      "Loading file: AlohaOe.wav\n",
      "Loading file: ASatisfiedMind.wav\n",
      "Loading file: BlueSuedeShoes.wav\n",
      "Loading file: DannyBoy.wav\n",
      "Loading file: Desperado.wav\n",
      "Loading file: FatherAndSon.wav\n",
      "Loading file: FolsomPrisonBlues.wav\n",
      "Loading file: FurtherOnUpTheRoad.wav\n",
      "Loading file: GhostRidersInTheSky.wav\n",
      "Loading file: GirlFromTheNorthCountry.wav\n",
      "Loading file: GiveMyLoveToRose.wav\n",
      "Loading file: GodsGonnaCutYouDown.wav\n",
      "Loading file: HeartOfGold.wav\n",
      "Loading file: Highwayman..wav\n",
      "Loading file: Hurt.wav\n",
      "Loading file: IDontHurtAnymore.wav\n",
      "Loading file: IHeardThatLonesomeWhistle.wav\n",
      "Loading file: InMyLife.wav\n",
      "Loading file: IWontBackDown.wav\n",
      "Loading file: ManInBlack.wav\n",
      "Loading file: OhLonesomeMe.wav\n",
      "Loading file: One.wav\n",
      "Loading file: OutAmongTheStars.wav\n",
      "Loading file: PersonalJesus.wav\n",
      "Loading file: RedemptionSong.wav\n",
      "Loading file: RingOfFire.wav\n",
      "Loading file: SheUsedToLoveMeALot.wav\n",
      "Loading file: SolitaryMan.wav\n",
      "Loading file: TheGeneralLee.wav\n",
      "Loading file: TheGettysburgAddress.wav\n",
      "Loading file: TheLegendOfJohnHenrysHammer.wav\n",
      "Loading file: TheManComesAround.wav\n",
      "Loading file: TheWanderer.wav\n",
      "Loading file: WayfaringStranger.wav\n",
      "Loading file: WellMeetAgain.wav\n",
      "Loading file: YouAreMySunshine.wav\n"
     ]
    }
   ],
   "source": [
    "def zip_label_wav():\n",
    "    reg_dir = os.getcwd() + '/Model_Data/songs/vocal_reg/'\n",
    "    iso_dir = os.getcwd() + '/Model_Data/songs/vocal_iso/'\n",
    "    label_dir = os.getcwd() + '/Model_Data/lyrics/'\n",
    "    reg_wav_list = []\n",
    "    iso_wav_list = []\n",
    "    label_list = []\n",
    "    # .label file\n",
    "    for filename in os.scandir(reg_dir):\n",
    "        with open(label_dir + filename.name.split('.')[0] + '.label', 'r') as r:\n",
    "            line = r.readline()\n",
    "            label_list.append(str(line).split(' '))\n",
    "        r.close()\n",
    "    label_torch = torch.from_numpy(np.array(label_list, dtype=np.float32))\n",
    "    print(label_torch.size())\n",
    "    # .wav file\n",
    "    for filename in os.scandir(reg_dir):\n",
    "        print(\"Loading file:\", filename.name)\n",
    "        reg_wav, reg_sr = librosa.load(filename.path, duration=120)\n",
    "        iso_wav, iso_sr = librosa.load(iso_dir + filename.name, duration=120)\n",
    "        reg_wav_list.append((reg_wav, reg_sr))\n",
    "        iso_wav_list.append((iso_wav, iso_sr))\n",
    "    \n",
    "    return label_torch, reg_wav_list, iso_wav_list\n",
    "\n",
    "label_torch, reg_wav_list, iso_wav_list = zip_label_wav()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note for Andy\n",
    "\n",
    "for label_torch, the size is (38, 120)\n",
    "if you need [1, 120] tensor each time, just do\n",
    "label_torch[i].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Total Loss: 301321.531\n",
      "Epoch 1 Total Loss: 2357.749\n",
      "Epoch 2 Total Loss: 2219.437\n",
      "Epoch 3 Total Loss: 2130.725\n",
      "Epoch 4 Total Loss: 2115.577\n",
      "Epoch 5 Total Loss: 2111.111\n",
      "Epoch 6 Total Loss: 2104.028\n",
      "Epoch 7 Total Loss: 2103.855\n"
     ]
    }
   ],
   "source": [
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build the neural network for classifying pauses against nonpauses\n",
    "class PauseNet1(nn.Module):\n",
    "  def __init__(self, num_mfccs, hid1, hid2, out):\n",
    "    super().__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc1 = nn.Linear(num_mfccs, hid1)\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    self.fc2 = nn.Linear(hid1, hid2)\n",
    "    torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    self.fc3 = nn.Linear(hid2, out)\n",
    "    torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "\n",
    "  # pass forward for nn\n",
    "  def forward(self, x):\n",
    "    x=self.relu(self.fc1(x))\n",
    "    x=self.relu(self.fc2(x))\n",
    "    x=self.sigmoid(self.fc3(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #set parameters\n",
    "    num_epochs = 30\n",
    "    num_mfccs = 20\n",
    "    hidden1_size = 100\n",
    "    hidden2_size = 25\n",
    "    out_size = 1\n",
    "\n",
    "    # set other constants\n",
    "    sr = 22050\n",
    "    hop_length = 512\n",
    "    song_dur = 120\n",
    "\n",
    "    # create neural network\n",
    "    pause_net = PauseNet1(num_mfccs, hidden1_size, hidden2_size, out_size)\n",
    "    optimizer = optim.Adam(pause_net.parameters(), lr=0.0005)\n",
    "    loss_func = nn.BCELoss()\n",
    "\n",
    "    # # get data\n",
    "    # generate_lyrics_label()\n",
    "    # # Pack the label and .wav file\n",
    "    # iso_labels, iso_wavs, reg_wavs = zip_label_wav()\n",
    "    # reg_wav = np.array(reg_wav_list)\n",
    "    # iso_wav = np.array(iso_wav_list)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for song_sr, labels in zip(reg_wav_list, label_torch):\n",
    "            song = song_sr[0]\n",
    "            # sample window of 2048 and hop size of 512 samples\n",
    "            mfccs = librosa.feature.mfcc(y=song, n_mfcc=num_mfccs) #(num_mfccs, 5168)\n",
    "\n",
    "            #breaks down mfccs into their time intervals\n",
    "            audio_length = len(song) / sr # in seconds\n",
    "            step = hop_length / sr # in seconds\n",
    "            intervals_s = np.arange(0, audio_length, step)\n",
    "\n",
    "            # get each second and sample\n",
    "            for label in labels:\n",
    "                #allows me to easily find the cutoff\n",
    "                intervals_s -= 1\n",
    "                #isolate a single second\n",
    "                sec_interval = np.where(intervals_s < 0)[0]\n",
    "                # indexes a single second of song from MFCCs\n",
    "                song_sec = np.take(mfccs, sec_interval, axis=1)\n",
    "\n",
    "                #average the values over a second\n",
    "                inp = torch.from_numpy(np.mean(song_sec, axis=1))\n",
    "\n",
    "                label_tensor = torch.tensor([label])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = pause_net.forward(inp)\n",
    "\n",
    "                # nonpause proper label is 0, pause proper label is 1\n",
    "                loss = loss_func(pred, label_tensor)\n",
    "                total_loss += loss\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        print(\"Epoch %i Total Loss: %.3f\" % (epoch, total_loss))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52469ae204d1d50c448c04334a11ed7bbfc3a11760631521f4bdc0e8f20089d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
